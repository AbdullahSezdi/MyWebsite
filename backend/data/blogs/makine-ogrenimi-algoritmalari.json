{
  "slug": "makine-ogrenimi-algoritmalari",
  "title": "Makine Öğrenimi Algoritmalarını Nasıl Seçmeliyiz?",
  "summary": "Makine öğrenimi projelerinde algoritma seçimi konusunda kapsamlı bir rehber. Veri tipinden model performansına, yorumlanabilirlikten pratik örneklere kadar temel bilgiler.",
  "category": "Veri Bilimi",
  "readTime": "15",
  "publishDate": "2024-03-21",
  "image": "/images/blog/machine-learning.svg",
  "tags": ["Makine Öğrenimi", "Veri Bilimi", "Algoritma Seçimi"],
  "content": "# Makine Öğrenimi Algoritmalarını Nasıl Seçmeliyiz?\n## Projelerde Algoritma Seçiminin Püf Noktaları\n\nMakine öğrenimi projelerine ilk adımımı attığımda en çok zorlandığım konulardan biri, \"Bu problemde hangi algoritmayı kullansam?\" sorusuydu. O kadar çok seçenek var ki insanın kafası karışabiliyor. Bu yazıda, ben de kendi öğrendiklerimi size aktarmak istiyorum. Umarım işinize yarar!\n\n------------------------------------\n## 1. Problemin Tipine Göre Algoritma Seçimi\n------------------------------------\nİlk soru: \"Ne yapmaya çalışıyorum?\"\n- Sınıflandırma (Classification): E-postaların spam olup olmadığını belirlemek, görsellerdeki nesneleri etiketlemek vs.\n- Regresyon (Regression): Ev fiyatı tahmini, satış miktarı tahmini gibi sürekli değerler.\n- Kümelendirme (Clustering): Müşteri segmentasyonu, benzer içerikleri gruplama.\n- Zaman Serisi (Time Series): Hisse senedi tahmini, hava durumu tahmini gibi zaman bazlı veriler.\n- Öneri Sistemleri (Recommendation Systems): Kullanıcılara ürün veya içerik öneren sistemler.\n\nSorunun hangi kategoriye girdiğini bilince, hangi algoritmaların bu alanda \"iyi bilinen\" yöntemler olduğunu kolayca bulabiliyoruz. Mesela, sınıflandırma varsa Lojistik Regresyon, Karar Ağaçları, Random Forest ya da XGBoost sıklıkla deneniyor.\n\n------------------------------------\n## 2. Veri Miktarı ve Kalitesi\n------------------------------------\nVeri = Yakıt gibi düşünebiliriz. Ama bu veri ne kadar temiz, ne kadar büyük, ne kadar dengeli?\n\n### a) Küçük veya Orta Ölçekli Veri\n- Genellikle basit algoritmalarla (Lojistik/Doğrusal Regresyon, Karar Ağacı gibi) iyi sonuçlar alınabilir.\n- Basit modeller hızlı eğitilir, sonuçlarını anlaması kolaydır.\n\n### b) Büyük Ölçekli Veri\n- Milyonlarca veri varsa, bazen derin öğrenme (Neural Networks) veya dağıtık (distributed) yöntemler (mesela Spark ML) kullanmak daha mantıklı olur.\n- Boosting algoritmaları (XGBoost, LightGBM) da büyük veride ve karmaşık ilişkilerde genelde iyi performans gösterir.\n\n### c) Veri Kalitesi\n- Eksik değerler, uç değerler (outliers) veya dengesizlik (örneğin veri setinin %1'i pozitif, %99'u negatif) gibi durumlar algoritma seçimini etkileyebilir.\n- Bazı modeller eksik değerlere karşı daha toleranslıdır (Random Forest gibi), bazıları ise verinin düzgün bir şekilde temizlenmesini ister (Lojistik/Doğrusal Regresyon).\n\n------------------------------------\n## 3. Yorumlanabilirlik mi Performans mı?\n------------------------------------\nJunior biri olarak, önce \"en yüksek doğruluk\" peşinde koşuyordum. Ancak proje gerçek hayatta kullanılırken \"Bu modeli nasıl anlatacağız?\" sorusu var. Mesela bankada kredi başvurusunu reddeden bir modeli, müşteriye veya üst düzeye açıklayabilmek önemli.\n\n- Basit Modeller (Lojistik/Doğrusal Regresyon):\n  Katsayılardan hangi değişkenin nasıl etki ettiğini az çok görebiliyoruz. \"Gelir arttıkça kredi onaylanma şansı şu kadar artar\" gibi açıklamalar yapmak kolay.\n- Karar Ağaçları:\n  Ağaç yapısını görselleştirip \"Şu özelliğin şu değerden büyük olması durumunda şuna gidiyoruz\" diye anlatabiliyoruz.\n- Random Forest, XGBoost, Derin Öğrenme:\n  Genelde daha yüksek performans verebiliyor. Ama sonuçları yorumlamak çoook daha zor. SHAP, LIME gibi yöntemler kullansak da yine de \"siyah kutu\" (black box) hissiyatı oluyor.\n\nProjenin gerektirdiği şeffaflık düzeyine göre seçim yapmak faydalı.\n\n------------------------------------\n## 4. Performans Metrikleri\n------------------------------------\nModelinizi hangi metrikle değerlendireceğiniz de algoritma seçiminizi kısmen etkileyebilir.\n\n- Accuracy (Doğruluk): Bazen güzel, ama dengesiz veri setinde (ör. %99 normal, %1 anormal) yanıltıcı olabilir.\n- Precision / Recall: Sahtekarlık tespiti (fraud detection) gibi alanlarda çok önemli. Yanlış pozitif-yanlış negatif dengesi kritik oluyor.\n- F1 Skoru: Precision ve Recall'ü birlikte değerlendirmeyi sağlar.\n- ROC AUC: Sınıflandırma problemlerinde farklı eşik değerlerinde modelin performansını görebiliriz.\n- MSE (Mean Squared Error), MAE (Mean Absolute Error): Regresyon problemleri için. Hangisiyle rahat ediyorsanız onunla başlayın.\n\nÖrnek: Bir e-ticaret sitesinde fraud (sahtekarlık) tespiti yapıyorsunuz. Veri dengesiz. Accuracy %99 bile olsa, belki fraud'ları bulamıyor. O yüzden Recall ya da Precision-Recall daha önemli hale geliyor.\n\n------------------------------------\n## 5. Ufak Bir Örnek: Ev Fiyatı Tahmini\n------------------------------------\n### Senaryo\n- Evin metrekare alanı, oda sayısı, bulunduğu semt, bina yaşı vb. özellikler var.\n- İstediğimiz: Evin satış fiyatını tahmin etmek.\n\n### Algoritma Adayları\n- Doğrusal Regresyon (Linear Regression):\n  Basit, hızlı, yorumlaması kolay. \"Oda sayısı +1 arttığında ortalama fiyat şu kadar artıyor\" diyebiliyorsunuz.\n- Karar Ağaçları (Regression Trees):\n  Özellikler arasındaki ilişkiler karmaşıksa ağaçlar daha esnek olabilir.\n- Random Forest / XGBoost:\n  Genelde daha isabetli sonuç veriyor, ancak yorumlamak ve hiperparametre ayarlamak biraz daha uğraştırıcı.\n- Derin Öğrenme:\n  Çok fazla veri varsa ve özellikler karmaşık ilişkiler içeriyorsa. Fakat bu senaryoda genelde daha basit yöntemlerle de iyi performans alınabiliyor.\n\nBaşlangıç: Küçük bir veri setiniz varsa, önce Doğrusal Regresyon deneyin, olmazsa Karar Ağaçları veya Random Forest'la bir adım ileri gidin.\n\n------------------------------------\n## 6. Adım Adım Yaklaşım (Junior Tavsiyeleri)\n------------------------------------\n1. Veriyi Tanıyın\n   - Eksik değer var mı, aykırı değer var mı, veri tipleri nasıl?\n   - Dengesiz veri var mı? (Sınıf dağılımlarını kontrol edin.)\n\n2. Temel bir Model Kurun\n   - \"Baseline\" olarak Lojistik/Doğrusal Regresyon veya basit bir Karar Ağacı.\n   - Elde ettiğiniz ilk sonuçlar, sonraki modellerle kıyaslama için referans noktası olur.\n\n3. Model İyileştirme\n   - Mevcut modeli \"Cross Validation\" ile doğrulayın (mesela K-Fold CV).\n   - Hiperparametre optimizasyonu (Grid Search, Random Search, vs.) uygulayın.\n   - Özellik mühendisliği (feature engineering) yapın. Mesela \"metrekare başına fiyat\" gibi yeni bir özellik türetin.\n\n4. Farklı Algoritmalar Deneyin\n   - Sonuçları tabloya yazın (Accuracy, F1, MSE vs. hangi metrik uygunsa).\n   - Eğer çok benzer sonuçlar alıyorsanız, karmaşık modele geçmek yerine basit modeli tercih edebilirsiniz (yorumlanabilirlik ve hız avantajı!).\n\n5. Model Seçin ve Uygulamaya Alın\n   - Mümkünse \"model interpretasyonu\" yapın. İş birimlerine anlatmanız gerekebilir.\n   - Gerçek hayatta gelen yeni verilerle modeli düzenli aralıklarla güncelleyin.\n\n------------------------------------\n## 7. Son Söz\n------------------------------------\nMakine öğreniminde algoritma seçimi, sabit bir reçete gibi değil de deneme-yanılma ve deneyim işidir. Ben de hala öğreniyorum ve her projede ufak farklılıklar çıkabiliyor. Yine de şu üç ipucu bana her zaman yol gösterici oldu:\n\n1) Problemi doğru tanımla: Sınıflandırma mı, regresyon mu, dengesiz mi, büyük mü, küçük mü?\n2) Basit bir modelle başla: Hızlı sonuç verir, sorunları erkenden görürsün.\n3) Sürekli iyileştir: Veri ön işleme, özellik seçimi, hiperparametre tuning...\n\nUmarım anlatıklarım işinize yarar. Unutmayın, asıl ustalık veriyle bol bol pratik yapmakta gizli. Bol şans!"
} 